{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969ccf3a",
   "metadata": {},
   "source": [
    "## Reading the previously analized and prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13594bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10128e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CrimesFix\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"16\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b0428f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "data_dir = '../Datasets/'\n",
    "file_crimes = data_dir + '3_crimes_cleaned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb14590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = spark.read.parquet(file_crimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "846fc3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_clean - number of rows: 7474272\n",
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Day: integer (nullable = true)\n",
      " |-- Hour: integer (nullable = true)\n",
      " |-- Minute: integer (nullable = true)\n",
      " |-- IUCR_Num: integer (nullable = true)\n",
      " |-- Primary_Type_Num: integer (nullable = true)\n",
      " |-- Location_Description_Num: integer (nullable = true)\n",
      " |-- Arrest: integer (nullable = true)\n",
      " |-- Domestic: integer (nullable = true)\n",
      " |-- Beat: integer (nullable = true)\n",
      " |-- District: integer (nullable = true)\n",
      " |-- Ward: integer (nullable = true)\n",
      " |-- Community_Area: integer (nullable = true)\n",
      " |-- FBI_Code_Num: integer (nullable = true)\n",
      "\n",
      "+----+-----+---+----+------+--------+----------------+------------------------+------+--------+----+--------+----+--------------+------------+\n",
      "|Year|Month|Day|Hour|Minute|IUCR_Num|Primary_Type_Num|Location_Description_Num|Arrest|Domestic|Beat|District|Ward|Community_Area|FBI_Code_Num|\n",
      "+----+-----+---+----+------+--------+----------------+------------------------+------+--------+----+--------+----+--------------+------------+\n",
      "|2003|    2| 16|  14|    38|      48|               7|                       0|     0|       0|2514|      25|  31|            19|           7|\n",
      "|2001|    1| 11|   4|    30|      77|              21|                       2|     1|       1| 333|       3|   5|            43|          22|\n",
      "|2001|    1| 19|   1|     7|      77|              21|                       0|     1|       0|1724|      17|  33|            16|          22|\n",
      "|2001|    2|  5|  13|    45|      77|              21|                     141|     1|       0|2412|      24|  50|             2|          22|\n",
      "|2001|    2|  2|   8|    27|      15|               3|                       0|     1|       0|1523|      15|  29|            25|           4|\n",
      "|2001|    2|  3|  18|    52|      44|               7|                       0|     0|       0|1134|      11|  28|            27|           7|\n",
      "|2001|    2|  3|  21|    22|      10|               3|                       4|     1|       0|1121|      11|  26|            23|           4|\n",
      "|2001|    2|  2|   6|    30|       7|               7|                       0|     0|       0|2511|      25|  36|            19|           7|\n",
      "|2001|    2| 11|   8|    30|      77|              21|                      91|     1|       0|1531|      15|  28|            25|          22|\n",
      "|2001|    2| 13|   7|    45|       7|               7|                       0|     0|       0| 815|       8|  23|            56|           7|\n",
      "+----+-----+---+----+------+--------+----------------+------------------------+------+--------+----+--------+----+--------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking data\n",
    "print(f'df_clean - number of rows: {df_clean.count()}')\n",
    "df_clean = df_clean.drop('IUCR', 'Primary_Type', 'Location_Description', 'FBI_Code')\n",
    "df_clean.printSchema()\n",
    "df_clean.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f80f7",
   "metadata": {},
   "source": [
    "Since we already indexed the relevant categorical columns, we can skip the String Indexer phase of the pipeline we are creating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5e54f",
   "metadata": {},
   "source": [
    "The following columns were already indexed the previous notebook:\n",
    "\n",
    "IUCR_Num\n",
    "\n",
    "Primary_Type_Num\n",
    "\n",
    "Location_Description_Num\n",
    "\n",
    "FBI_Code_Num_Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c77b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_categorical = ['IUCR_Num', 'Primary_Type_Num', 'Location_Description_Num', 'Arrest', 'Domestic', 'Beat',  'District', 'Ward', 'Community_Area', 'FBI_Code_Num']\n",
    "\n",
    "cols_numeric = [col for col in df_clean.columns if col not in cols_categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b7ae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['IUCR_Num', 'Primary_Type_Num', 'Location_Description_Num', 'Arrest', 'Domestic', 'Beat', 'District', 'Ward', 'Community_Area', 'FBI_Code_Num']\n",
      "Numeric columns: ['Year', 'Month', 'Day', 'Hour', 'Minute']\n"
     ]
    }
   ],
   "source": [
    "print(f'Categorical columns: {cols_categorical}')\n",
    "print(f'Numeric columns: {cols_numeric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff317009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['IUCR_Num', 'Primary_Type_Num', 'Location_Description_Num', 'Domestic', 'Beat', 'District', 'Ward', 'Community_Area', 'FBI_Code_Num']\n"
     ]
    }
   ],
   "source": [
    "cols_not_features = ['Arrest']\n",
    "\n",
    "\n",
    "categorical_cols = [i for i in cols_categorical if i not in cols_not_features]\n",
    "print(f'Categorical columns: {categorical_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37e3832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "non_categorical_cols = [i for i in cols_numeric if i not in cols_not_features]\n",
    "ohe_output_cols = [x + ' OHE' for x in categorical_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4ee829c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembler inputs: ['IUCR_Num OHE', 'Primary_Type_Num OHE', 'Location_Description_Num OHE', 'Domestic OHE', 'Beat OHE', 'District OHE', 'Ward OHE', 'Community_Area OHE', 'FBI_Code_Num OHE', 'Year', 'Month', 'Day', 'Hour', 'Minute']\n"
     ]
    }
   ],
   "source": [
    "ohe_encoder = OneHotEncoder(inputCols=categorical_cols, outputCols=ohe_output_cols, handleInvalid=\"keep\")\n",
    "assembler_inputs = ohe_output_cols + non_categorical_cols\n",
    "print(f'Assembler inputs: {assembler_inputs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9221d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vec_assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6ae71b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5232322 rows in the training set and 2241950 rows in the validation set.\n"
     ]
    }
   ],
   "source": [
    "df_train, df_validation = df_clean.randomSplit([0.7, 0.3], 42)\n",
    "\n",
    "print(f'There are {df_train.count()} rows in the training set and {df_validation.count()} rows in the validation set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfbc61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.write.mode('overwrite').parquet('../Datasets/crimes-small-train')\n",
    "df_validation.write.mode('overwrite').parquet('../Datasets/crimes-small-validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d5402da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_clean' in locals():\n",
    "    del df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09f08772",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(maxIter=10, regParam=0.1, labelCol='Arrest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "436de977",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[ohe_encoder, vec_assembler, lsvc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84a22471",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.write().overwrite().save('../Datasets/pipeline-LinearSVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0f158c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+------+--------+----------------+------------------------+------+--------+----+--------+----+--------------+------------+\n",
      "|Year|Month|Day|Hour|Minute|IUCR_Num|Primary_Type_Num|Location_Description_Num|Arrest|Domestic|Beat|District|Ward|Community_Area|FBI_Code_Num|\n",
      "+----+-----+---+----+------+--------+----------------+------------------------+------+--------+----+--------+----+--------------+------------+\n",
      "|2001|    1|  1|   0|     0|      26|               8|                       4|     0|       0|2424|      24|  49|             1|           8|\n",
      "|2001|    1|  1|   0|     0|      27|               0|                       1|     0|       0| 522|       5|  34|            49|           0|\n",
      "|2001|    1|  1|   0|     0|      27|               0|                       1|     0|       0|2222|      22|  21|            71|           0|\n",
      "|2001|    1|  1|   0|     0|      27|               0|                       2|     0|       0|2024|      20|  48|             3|           0|\n",
      "|2001|    1|  1|   0|     0|      52|              22|                       1|     0|       0|1723|      17|  33|            14|          16|\n",
      "|2001|    1|  1|   0|     0|     104|              15|                      38|     0|       0|1022|      10|  24|            29|          17|\n",
      "|2001|    1|  1|   0|     1|      68|               0|                      41|     0|       0|2522|      25|  37|            19|           0|\n",
      "|2001|    1|  1|   0|     1|     104|              15|                       1|     0|       0| 934|       9|  16|            61|          17|\n",
      "|2001|    1|  1|   0|     1|     113|              13|                       1|     0|       0|2535|      25|  30|            23|          18|\n",
      "|2001|    1|  1|   9|     0|       4|               0|                      17|     1|       0| 111|       1|  42|            32|           0|\n",
      "+----+-----+---+----+------+--------+----------------+------------------------+------+--------+----+--------+----+--------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb3afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_rows = 100000\n",
    "model = pipeline.fit(df_train.limit(limit_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1140527",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save('model-LinearSVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7628e3",
   "metadata": {},
   "source": [
    "# DELETE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2a2d564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Year=2001, Month=1, Day=1, Hour=0, Minute=0, IUCR_Num=27, Primary_Type_Num=0, Location_Description_Num=1, Arrest=0, Domestic=0, Beat=1024, District=10, Ward=24, Community_Area=30, FBI_Code_Num=0)\n"
     ]
    }
   ],
   "source": [
    "single_row = df_validation.limit(1).collect()[0]\n",
    "print(single_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbcf1186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Arrest: long (nullable = true)\n",
      " |-- Beat: long (nullable = true)\n",
      " |-- Community_Area: long (nullable = true)\n",
      " |-- Day: long (nullable = true)\n",
      " |-- District: long (nullable = true)\n",
      " |-- Domestic: long (nullable = true)\n",
      " |-- FBI_Code_Num: long (nullable = true)\n",
      " |-- Hour: long (nullable = true)\n",
      " |-- IUCR_Num: long (nullable = true)\n",
      " |-- Location_Description_Num: long (nullable = true)\n",
      " |-- Minute: long (nullable = true)\n",
      " |-- Month: long (nullable = true)\n",
      " |-- Primary_Type_Num: long (nullable = true)\n",
      " |-- Ward: long (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      " |-- IUCR_Num OHE: vector (nullable = true)\n",
      " |-- Primary_Type_Num OHE: vector (nullable = true)\n",
      " |-- Location_Description_Num OHE: vector (nullable = true)\n",
      " |-- Domestic OHE: vector (nullable = true)\n",
      " |-- Beat OHE: vector (nullable = true)\n",
      " |-- District OHE: vector (nullable = true)\n",
      " |-- Ward OHE: vector (nullable = true)\n",
      " |-- Community_Area OHE: vector (nullable = true)\n",
      " |-- FBI_Code_Num OHE: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert single_row to a DataFrame before transforming\n",
    "\n",
    "#df_predictions = model.transform(df_validation)\n",
    "\n",
    "df_single_row = spark.createDataFrame([single_row.asDict()])\n",
    "df_predictions = model.transform(df_single_row)\n",
    "\n",
    "# Check its schema\n",
    "df_predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98fe6967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric areaUnderROC = 0.0\n"
     ]
    }
   ],
   "source": [
    "df_predictions_eval = df_predictions.select('features', \n",
    "                    'rawPrediction', 'prediction', 'Arrest')\n",
    "\n",
    "binary_evaluator = BinaryClassificationEvaluator(labelCol='Arrest',\n",
    "                                                rawPredictionCol='rawPrediction',\n",
    "                                                metricName='areaUnderROC')\n",
    "    \n",
    "area_under_ROC = binary_evaluator.evaluate(df_predictions_eval)\n",
    "\n",
    "# Print out result\n",
    "print(f'Metric areaUnderROC = {area_under_ROC}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11ec3130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----+\n",
      "|prediction|Arrest|count|\n",
      "+----------+------+-----+\n",
      "|       0.0|     0|    1|\n",
      "+----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting of the kind of predictions made\n",
    "df_confusion_matrix = df_predictions_eval.groupBy('prediction', 'Arrest').count()\n",
    "df_confusion_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c7ff8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 0.0, 'TN': 1.0, 'FP': 0.0, 'FN': 0.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the confusion matrix\n",
    "tp = df_confusion_matrix.filter((F.col('prediction')==1.0) & (F.col('Arrest')==1)).first()\n",
    "tn = df_confusion_matrix.filter((F.col('prediction')==0.0) & (F.col('Arrest')==0)).first()\n",
    "fp = df_confusion_matrix.filter((F.col('prediction')==1.0) & (F.col('Arrest')==0)).first()\n",
    "fn = df_confusion_matrix.filter((F.col('prediction')==0.0) & (F.col('Arrest')==1)).first()\n",
    "\n",
    "confmat = {'TP': 0.0, 'TN': 0.0, 'FP': 0.0, 'FN': 0.0}\n",
    "if (tp):\n",
    "    confmat['TP'] = tp['count'] * 1.0\n",
    "if (tn):\n",
    "    confmat['TN'] = tn['count'] * 1.0\n",
    "if (fp):\n",
    "    confmat['FP'] = fp['count'] * 1.0\n",
    "if (fn):\n",
    "    confmat['FN'] = fn['count'] * 1.0\n",
    "\n",
    "confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07f268c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics based on the confusion matrix:\n",
      " Accuracy = 1.0\n",
      " Precision = 0.0\n",
      " Recall = 0.0\n",
      " Specifity = 1.0\n",
      " F1 score = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Based on the confusion matrix, computed the evaluation matrics:\n",
    "#   accuracy, precision, recall, specifity and F1 score\n",
    "\n",
    "# PS: Check divisons by 0.0\n",
    "TP = confmat['TP']\n",
    "TN = confmat['TN']\n",
    "FP = confmat['FP']\n",
    "FN = confmat['FN']\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0.0\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "specifity = TN / (TN + FP) if (TN + FP) > 0 else 0.0\n",
    "f1score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "print('Evaluation metrics based on the confusion matrix:')\n",
    "print(f' Accuracy = {accuracy}')\n",
    "print(f' Precision = {precision}')\n",
    "print(f' Recall = {recall}')\n",
    "print(f' Specifity = {specifity}')\n",
    "print(f' F1 score = {f1score}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
