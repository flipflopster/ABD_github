{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Algoritmos para Big Data\n",
    "\n",
    "**Handout 7 - Recommendation system**\n",
    "\n",
    "**2024/25**\n",
    "\n",
    "This lab class is about creating and using a recommendation system for books, with particular\n",
    "interest on the collaborative filtering strategy.\n",
    "\n",
    "This notebook should contain only the implementation of the tasks B and C presented in the handout, that is, focussing on the recommendation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task B - Data supporting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasets**\n",
    "\n",
    "After task A, there should be parquet files for users, books and ratings, with normal and smaller sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SparkSession\n",
    "spark = SparkSession.builder.appName(\"RecommendationSystem\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading and checking data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to read\n",
    "data_dir = '../.'\n",
    "file_users = data_dir + \n",
    "file_books = data_dir + \n",
    "file_ratings = data_dir + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading users data\n",
    "df_users = spark.read.parquet(file_users)\n",
    "\n",
    "# Checking data\n",
    "print(f'df_users - number of rows: {df_users.count()}')\n",
    "df_users.printSchema()\n",
    "df_users.show(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading books data\n",
    "df_books = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading ratings data\n",
    "df_ratings = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2.\n",
    "\n",
    "**Check the data quality. Is it really clean?**\n",
    "\n",
    "Leave aside outiliers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_users\n",
    "print(f'df_users - number of rows is {df_users.count() }; after dropDuplicates() applied would be {df_users.dropDuplicates().count()}.')\n",
    "print(f'''df_users - number of rows after dropna(how='any') would be {df_users.dropna(how='any').count()}.''')\n",
    "print('Checking nulls at each column of df_clean')\n",
    "dict_nulls = {col: df_users.filter(df_users[col].isNull()).count() for col in df_users.columns}\n",
    "dict_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task C - ML recommendation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1.\n",
    "\n",
    "**Feature enginnering**\n",
    "- Defining features to be used in the creation of the model\n",
    "- Use of StringIndexer() to transform categorical features into numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StringerIndexer for ISBN, with output column as ISBNi and handle invalid as keep\n",
    "# See https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StringIndexer.html\n",
    "indexer = StringIndexer(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns from df_ratings to be considered in the model\n",
    "user_feature = 'UserID'\n",
    "item_feature = 'ISBNi' \n",
    "rating_feature = 'BookRating'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. to 6.\n",
    "\n",
    "**Select and train the model**\n",
    "- Train/validation split: creation of two dataframes for training and validation respectively, with a split size of 70/30 (%)\n",
    "- Free memory space of the no longer needed initial dataframe\n",
    "- Set the ALS algorithm as estimator\n",
    "    - See details in http://spark.apache.org/docs/latest/ml-collaborative-filtering.html , like the main assumptions the implemented algorithm relies upon. For example, notice that:\n",
    "        - it underlies a collaborative filtering strategy;\n",
    "        - it aims to fill in the missing entries of a user-item association matrix, in which users and items are described by a small set of latent factors that can be used to predict missing entries. The latent factors are learned by the ALS algorithm.\n",
    "- Set up a ML pipeline configuration, holding the sequence of the two stages previously set:\n",
    "    1. String indexer\n",
    "    2. ML estimator (ALS)\n",
    "- Create the model by fitting the pipeline to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:31.983392Z",
     "start_time": "2021-03-07T19:11:30.973303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train/validation ratings split, with a random split of 70%, 30%\n",
    "df_train, df_validation = df_ratings.randomSplit\n",
    "\n",
    "# caching data ... but just the training part and if we want to (check the implications)\n",
    "# df_train.cache()\n",
    "\n",
    "# print the number of rows in each part\n",
    "print(f'There are {df_train.count()} rows in the training set and {df_validation.count()} in the validation set.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train/validation split as parquet files, say named as ratings-train and ratings-validation\n",
    "df_train.write.\n",
    "df_validation.write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ALS estimator to learn from the training data and consequently to build the model\n",
    "# note that we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, regParam=0.01, \n",
    "          userCol=user_feature, \n",
    "          itemCol=item_feature, \n",
    "          ratingCol=rating_feature,\n",
    "          coldStartStrategy=\"drop\",\n",
    "          implicitPrefs=True\n",
    "         )\n",
    "\n",
    "# if the rating matrix is derived from another source of information\n",
    "# (i.e. it is inferred from other signals), we may set implicitPrefs\n",
    "# to True to get better results (see ALS documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:32.970301Z",
     "start_time": "2021-03-07T19:11:32.967223Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The pipeline holds two stages set above\n",
    "# As we will see below, we are going to use it just for evaluation purposes\n",
    "pipeline = Pipeline(stages=[indexer, als])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pipeline with name pipeline-recommendation, for further use should it be required\n",
    "pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model (as transformer) by fitting the pipeline to training data. It may take time!\n",
    "model = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model with name model-recommendation, for further use should it be required.\n",
    "model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.\n",
    "\n",
    "**Evaluate the model** \n",
    "\n",
    "- Make predictions by applying the validation data to the model transformer\n",
    "- Print out the schema and content of the resulting dataframe\n",
    "- Compute the evaluation metric *rmse* using *RegressionEvaluator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:33.280981Z",
     "start_time": "2021-03-07T19:11:32.971571Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on validation data and show values of columns of interest\n",
    "df_prediction = model.transform(df_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out its schema and content\n",
    "df_prediction.printSchema()\n",
    "df_prediction.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the RMSE on the validation data, providing information regarding the label column and the prediction column\n",
    "# See https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.RegressionEvaluator.html\n",
    "evaluator = RegressionEvaluator(\n",
    "\n",
    "rmse = evaluator.evaluate(df_prediction)\n",
    "print(f'Root-mean-square error is {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task D - Model deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommendations**\n",
    "\n",
    "The ALS model allow us to get recommendations directly. So we will follow this approach instead of relying on the pipeline.\n",
    "\n",
    "See https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.recommendation.ALSModel.html \n",
    "\n",
    "for details, namely concerning the methods:\n",
    "- recommendForUserSubset(dataset, numItems)\n",
    "    - Returns top numItems items recommended for each user id in the input data set.\n",
    "- recommendForItemSubset(dataset, numUsers)\n",
    "    - Returns top numUsers users recommended for each item id in the input data set.\n",
    "\n",
    "\n",
    "\n",
    "Recall that we could achieve those results if working with predictions after the pipeline set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo the model without a pipeline\n",
    "df_train_indexed = indexer.fit(df_train).transform(df_train)\n",
    "direct_model = als.fit(df_train_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all distinct users and books in the training data, orderd by ID\n",
    "users = df_train_indexed.select(als.getUserCol()).distinct().orderBy('UserID', ascending=True)\n",
    "books = df_train_indexed.select(als.getItemCol()).distinct().orderBy('ISBNi', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_indexed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_indexed.orderBy('UserID', ascending=True).show()\n",
    "df_train_indexed.orderBy('ISBNi', ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall counting\n",
    "print(f'df_users - number of rows is {df_users.count()}.')\n",
    "print(f'users (distinct in model training) - number of rows is {users.count()}.')\n",
    "print(f'df_books - number of rows is {df_books.count()}.')\n",
    "print(f'books (distinct in model training) - number of rows is {books.count()}.')\n",
    "print(f'df_ratings - number of rows is {df_ratings.count()}.')\n",
    "print(f'train indexed - number of rows is {df_train_indexed.count()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train_indexed.select('ISBN', 'ISBNi').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join additional information to books\n",
    "books_ext = books.join(df, on='ISBNi', how='inner')\n",
    "print(f'books_ext - number of rows is {books_ext.count()}.')\n",
    "books_ext.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join additional information to books\n",
    "books_ext = books_ext.join(df_books, on='ISBN', how='inner')\n",
    "print(f'books_ext - number of rows is {books_ext.count()}.')\n",
    "books_ext.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join additional information to users\n",
    "users_ext = users.join(df_users, on='UserID', how='inner')\n",
    "print(f'users_ext - number of rows is {users_ext.count()}.')\n",
    "users_ext.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top 2 book recommendations for a specified subset of users, for example, 3 users who have smaller IDs \n",
    "top_n_books = 2\n",
    "num_users = 3\n",
    "subset_users = users.limit(3)\n",
    "books_recs = \n",
    "books_recs.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_recommendations = books_recs.select('UserID', F.explode('recommendations').alias('BookRecommendation'))\n",
    "books_recommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_recs = [ [row.UserID, row.BookRecommendation] for row in books_recommendations.collect()]\n",
    "list_recs = [[row.UserID, row.BookRecommendation['ISBNi'], row.BookRecommendation['rating']] for row in books_recommendations.collect()]\n",
    "list_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the recommendations with additional information\n",
    "for rec in list_recs:\n",
    "    info_user = users_ext.filter(users_ext.UserID == rec[0]).limit(1)\n",
    "    print('')\n",
    "    print('*** For user ***')\n",
    "    info_user.show()\n",
    "    print(f'Rating to be considered is {rec[2]}')\n",
    "    if rec[2] > 0:\n",
    "        print('Book recommendation is')\n",
    "        info_book = books_ext.filter(books_ext.ISBNi == rec[1]).limit(1)\n",
    "        info_book.show()\n",
    "    else:\n",
    "        print('No recommendation is advisable!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curiosity: check ratings about user 8\n",
    "df_ratings.filter(df_ratings.UserID == 8).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top 2 user recommendations for a specified subset of books, for example, 3 books that have smaller indexed IDs\n",
    "# Such users might be interested on the specified books \n",
    "top_n_users = 2\n",
    "num_books = 3\n",
    "subset_books = books.limit(3)\n",
    "users_recs = \n",
    "users_recs.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_recommendations = users_recs.select('ISBNi', F.explode('recommendations').alias('UserRecommendation'))\n",
    "users_recommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_recs = [ [row.ISBNi, row.UserRecommendation] for row in users_recommendations.collect()]\n",
    "list_recs = [[row.ISBNi, row.UserRecommendation['UserID'], row.UserRecommendation['rating']] for row in users_recommendations.collect()]\n",
    "list_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the recommendations with additional information\n",
    "for rec in list_recs:\n",
    "    info_book = books_ext.filter(books_ext.ISBNi == rec[0]).limit(1)\n",
    "    print('')\n",
    "    print('*** For book ***')\n",
    "    info_book.show()\n",
    "    print(f'Rating to be considered is {rec[2]}')\n",
    "    if rec[2] > 0:\n",
    "        print('User recommendation is (user might be interested on the book)')\n",
    "        info_user = users_ext.filter(users_ext.UserID == rec[1]).limit(1)\n",
    "        info_user.show()\n",
    "    else:\n",
    "        print('No recommendation is advisable!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curiosity: check ratings about book 0971880107\n",
    "df_ratings.filter(df_ratings.ISBN == '0971880107').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "249px",
    "width": "332px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.98px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
