{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Algoritmos para Big Data\n",
    "\n",
    "**Handout 2 -  Data joining, windowing, and Spark SQL**\n",
    "\n",
    "**2024/25**\n",
    "\n",
    "This lab class aims to get hands-on experience on three issues related to data processing: data joining, data windowing and Spark SQL.\n",
    "\n",
    "This notebook should contain the implementation of the tasks presented in the handout.\n",
    "\n",
    "Hence both handout and notebook must be considered together as one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task A - Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasest**\n",
    "\n",
    "The file can be downloaded from\n",
    "\n",
    "https://bigdata.iscte-iul.eu/datasets/retail-data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spark setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SparkSession\n",
    "spark = SparkSession.builder.appName(\"JoinWindowingSQL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading and checking data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo;StockCode;Description;Quantity;InvoiceDate;UnitPrice;CustomerID;Country\n",
      "536375;71053;WHITE METAL LANTERN;6;01/12/2010 09:32;3.39;17850;United Kingdom\n",
      "C536391;21983;PACK OF 12 BLUE PAISLEY TISSUES ;-24;01/12/2010 10:24;0.29;17548;United Kingdom\n",
      "536395;21314;SMALL GLASS HEART TRINKET POT;8;01/12/2010 10:47;2.1;13767;United Kingdom\n",
      "536396;82494L;WOODEN FRAME ANTIQUE WHITE ;12;01/12/2010 10:51;2.55;17850;United Kingdom\n",
      "536425;22837;HOT WATER BOTTLE BABUSHKA ;8;01/12/2010 12:08;4.65;13758;United Kingdom\n",
      "536464;20878;SET/9 CHRISTMAS T-LIGHTS SCENTED ;1;01/12/2010 12:23;1.25;17968;France\n",
      "536520;22760;TRAY, BREAKFAST IN BED;1;01/12/2010 12:43;12.75;14729;United Kingdom\n",
      "536520;22812;PACK 3 BOXES CHRISTMAS PANNETONE;3;01/12/2010 12:43;1.95;14729;United Kingdom\n",
      "536530;21071;VINTAGE BILLBOARD DRINK ME MUG;24;01/12/2010 13:21;1.25;17905;France\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "data_dir ='../../Datasets/'\n",
    "file_retail = data_dir + 'retail-data.csv'\n",
    "\n",
    "! head $file_retail\n",
    "df_retail = spark.read.csv(file_retail, header=True, sep=';', inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+----------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+----------------+---------+----------+--------------+\n",
      "|   536375|    71053| WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|United Kingdom|\n",
      "|  C536391|    21983|PACK OF 12 BLUE P...|     -24|01/12/2010 10:24|     0.29|     17548|United Kingdom|\n",
      "|   536395|    21314|SMALL GLASS HEART...|       8|01/12/2010 10:47|      2.1|     13767|United Kingdom|\n",
      "|   536396|   82494L|WOODEN FRAME ANTI...|      12|01/12/2010 10:51|     2.55|     17850|United Kingdom|\n",
      "|   536425|    22837|HOT WATER BOTTLE ...|       8|01/12/2010 12:08|     4.65|     13758|United Kingdom|\n",
      "|   536464|    20878|SET/9 CHRISTMAS T...|       1|01/12/2010 12:23|     1.25|     17968|        France|\n",
      "|   536520|    22760|TRAY, BREAKFAST I...|       1|01/12/2010 12:43|    12.75|     14729|United Kingdom|\n",
      "|   536520|    22812|PACK 3 BOXES CHRI...|       3|01/12/2010 12:43|     1.95|     14729|United Kingdom|\n",
      "|   536530|    21071|VINTAGE BILLBOARD...|      24|01/12/2010 13:21|     1.25|     17905|        France|\n",
      "|   536530|    22943|CHRISTMAS LIGHTS ...|       2|01/12/2010 13:21|     4.95|     17905|        France|\n",
      "+---------+---------+--------------------+--------+----------------+---------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "df_retail - number of rows is 3054.\n",
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_retail.show(10)\n",
    "print(f'df_retail - number of rows is {df_retail.count()}.')\n",
    "df_retail.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_retail - number of rows is 3054; after dropDuplicates() applied would be 3054.\n"
     ]
    }
   ],
   "source": [
    "print(f'df_retail - number of rows is {df_retail.count()  }; after dropDuplicates() applied would be {df_retail.dropDuplicates().count()   }.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_retail - number of rows after dropna(how='any') would be 3054.\n"
     ]
    }
   ],
   "source": [
    "print(f'''df_retail - number of rows after dropna(how='any') would be {df_retail.dropna(how='any').count()     }.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking nulls at each column of df_retail\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'InvoiceNo': 0,\n",
       " 'StockCode': 0,\n",
       " 'Description': 0,\n",
       " 'Quantity': 0,\n",
       " 'InvoiceDate': 0,\n",
       " 'UnitPrice': 0,\n",
       " 'CustomerID': 0,\n",
       " 'Country': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Checking nulls at each column of df_retail')\n",
    "dict_nulls_retail = {col: df_retail.filter(df_retail[col].isNull()).count() for col in df_retail.columns}\n",
    "dict_nulls_retail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data seems fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task B - Data joining\n",
    "\n",
    "Combining rows from two DataFrames, based on one common column. Types of operation to consider are:\n",
    "- Inner join\n",
    "- Left join\n",
    "- Full join\n",
    "- Cross join\n",
    "- Anti join\n",
    "\n",
    "Based on df_retail, three DataFrames will be created:\n",
    "- df_sales, as df_retail but excluding column Country\n",
    "- df_customers, with two columns: CustomerID and Country\n",
    "- df_customers_nonUK, likewise df_costumers but filtering out the customers from United Kingdom\n",
    "\n",
    "\n",
    "Common column as condition will be CustomerID.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|       Country|count|\n",
      "+--------------+-----+\n",
      "|       Germany|  116|\n",
      "|        France|  490|\n",
      "|          EIRE|   48|\n",
      "|        Norway|   95|\n",
      "|     Australia|  111|\n",
      "|United Kingdom| 2162|\n",
      "|   Netherlands|   32|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_retail.groupBy(\"Country\").count().show()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+----------------+---------+----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|CustomerID|\n",
      "+---------+---------+--------------------+--------+----------------+---------+----------+\n",
      "|   536375|    71053| WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|\n",
      "|  C536391|    21983|PACK OF 12 BLUE P...|     -24|01/12/2010 10:24|     0.29|     17548|\n",
      "|   536395|    21314|SMALL GLASS HEART...|       8|01/12/2010 10:47|      2.1|     13767|\n",
      "|   536396|   82494L|WOODEN FRAME ANTI...|      12|01/12/2010 10:51|     2.55|     17850|\n",
      "|   536425|    22837|HOT WATER BOTTLE ...|       8|01/12/2010 12:08|     4.65|     13758|\n",
      "|   536464|    20878|SET/9 CHRISTMAS T...|       1|01/12/2010 12:23|     1.25|     17968|\n",
      "|   536520|    22760|TRAY, BREAKFAST I...|       1|01/12/2010 12:43|    12.75|     14729|\n",
      "|   536520|    22812|PACK 3 BOXES CHRI...|       3|01/12/2010 12:43|     1.95|     14729|\n",
      "|   536530|    21071|VINTAGE BILLBOARD...|      24|01/12/2010 13:21|     1.25|     17905|\n",
      "|   536530|    22943|CHRISTMAS LIGHTS ...|       2|01/12/2010 13:21|     4.95|     17905|\n",
      "+---------+---------+--------------------+--------+----------------+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As df_retail but excluding the column Country\n",
    "df_sales = df_retail.drop('Country')\n",
    "df_sales.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After df_retail but with just two columns: CustomerID and Country\n",
    "df_customers = df_retail.select('CustomerID', 'Country').distinct().orderBy('Country')\n",
    "df_customers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_customers_nonUK - number of rows is 29.\n"
     ]
    }
   ],
   "source": [
    "# Likewise df_customers but filtering out the customers from United Kingdom\n",
    "df_customers_nonUK = df_customers.filter(df_customers.Country != 'United Kingdom')\n",
    "print(f'df_customers_nonUK - number of rows is {df_customers_nonUK.count()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------------------+--------+----------------+---------+---------+\n",
      "|CustomerID|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|  Country|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+---------+\n",
      "|     17968|   536464|    20878|SET/9 CHRISTMAS T...|       1|01/12/2010 12:23|     1.25|   France|\n",
      "|     17905|   536530|    21071|VINTAGE BILLBOARD...|      24|01/12/2010 13:21|     1.25|   France|\n",
      "|     17905|   536530|    22943|CHRISTMAS LIGHTS ...|       2|01/12/2010 13:21|     4.95|   France|\n",
      "|     12433|   536532|    22534|MAGIC DRAWING SLA...|      24|01/12/2010 13:24|     0.42|   Norway|\n",
      "|     22578|   536592|    22472|TV DINNER TRAY DO...|       3|01/12/2010 17:06|    11.02|  Germany|\n",
      "|     22578|   536592|    22620|4 TRADITIONAL SPI...|       2|01/12/2010 17:06|     2.51|  Germany|\n",
      "|     19997|   536592|   84536B|FAIRY CAKES NOTEB...|       1|01/12/2010 17:06|     0.85|Australia|\n",
      "|     21587|   536592|   85199L|LARGE HANGING IVO...|       1|01/12/2010 17:06|     1.28|   France|\n",
      "|     19555|   536592|   90214A|\"\"\"LETTER \"\"\"\"A\"\"...|       2|01/12/2010 17:06|     0.85|   France|\n",
      "|     19888|   536592|    20668|DISCO BALL CHRIST...|       6|01/12/2010 17:06|     0.43|Australia|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Inner join - number of rows is 892.\n"
     ]
    }
   ],
   "source": [
    "# Inner join\n",
    "df = df_sales.join(df_customers_nonUK, on='CustomerID',how='inner')\n",
    "df.show(10)\n",
    "print(f'Inner join - number of rows is {df.count()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------------------+--------+----------------+---------+-------+\n",
      "|CustomerID|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|Country|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+-------+\n",
      "|     17850|   536375|    71053| WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|   NULL|\n",
      "|     17548|  C536391|    21983|PACK OF 12 BLUE P...|     -24|01/12/2010 10:24|     0.29|   NULL|\n",
      "|     13767|   536395|    21314|SMALL GLASS HEART...|       8|01/12/2010 10:47|      2.1|   NULL|\n",
      "|     17850|   536396|   82494L|WOODEN FRAME ANTI...|      12|01/12/2010 10:51|     2.55|   NULL|\n",
      "|     13758|   536425|    22837|HOT WATER BOTTLE ...|       8|01/12/2010 12:08|     4.65|   NULL|\n",
      "|     17968|   536464|    20878|SET/9 CHRISTMAS T...|       1|01/12/2010 12:23|     1.25| France|\n",
      "|     14729|   536520|    22760|TRAY, BREAKFAST I...|       1|01/12/2010 12:43|    12.75|   NULL|\n",
      "|     14729|   536520|    22812|PACK 3 BOXES CHRI...|       3|01/12/2010 12:43|     1.95|   NULL|\n",
      "|     17905|   536530|    21071|VINTAGE BILLBOARD...|      24|01/12/2010 13:21|     1.25| France|\n",
      "|     17905|   536530|    22943|CHRISTMAS LIGHTS ...|       2|01/12/2010 13:21|     4.95| France|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Left join - number of rows is 3054.\n"
     ]
    }
   ],
   "source": [
    "# Left join\n",
    "df = df_sales.join(df_customers_nonUK, on='CustomerID',how='left')\n",
    "df.show(10)\n",
    "print(f'Left join - number of rows is {df.count()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------------------+--------+----------------+---------+---------+\n",
      "|CustomerID|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|  Country|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+---------+\n",
      "|     12431|   536389|    22941|CHRISTMAS LIGHTS ...|       6|01/12/2010 10:03|      8.5|Australia|\n",
      "|     12431|   536389|    22193|RED DINER WALL CLOCK|       2|01/12/2010 10:03|      8.5|Australia|\n",
      "|     12431|   536389|    21791|VINTAGE HEADS AND...|      12|01/12/2010 10:03|     1.25|Australia|\n",
      "|     12431|   536389|    22726|ALARM CLOCK BAKEL...|       4|01/12/2010 10:03|     3.75|Australia|\n",
      "|     12431|   536389|    22727|ALARM CLOCK BAKEL...|       4|01/12/2010 10:03|     3.75|Australia|\n",
      "|     12431|   536389|    22195|LARGE HEART MEASU...|      24|01/12/2010 10:03|     1.65|Australia|\n",
      "|     12431|   536389|   35004G|SET OF 3 GOLD FLY...|       4|01/12/2010 10:03|     6.35|Australia|\n",
      "|     12431|   536389|   85014B|RED RETROSPOT UMB...|       6|01/12/2010 10:03|     5.95|Australia|\n",
      "|     12431|   536389|   85014A|BLACK/BLUE POLKAD...|       3|01/12/2010 10:03|     5.95|Australia|\n",
      "|     12431|   536389|    22191|IVORY DINER WALL ...|       2|01/12/2010 10:03|      8.5|Australia|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Full join - number of rows is 3054.\n"
     ]
    }
   ],
   "source": [
    "# Full join\n",
    "df = df_sales.join(df_customers_nonUK, on='CustomerID',how='full')\n",
    "df.show(10)\n",
    "print(f'Full join - number of rows is {df.count()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+--------+----------------+---------+----------+----------+-----------+\n",
      "|InvoiceNo|StockCode|        Description|Quantity|     InvoiceDate|UnitPrice|CustomerID|CustomerID|    Country|\n",
      "+---------+---------+-------------------+--------+----------------+---------+----------+----------+-----------+\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     19588|Netherlands|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     18444|     France|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     19888|  Australia|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     20145|  Australia|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     21365|    Germany|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     17873|     France|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     19997|  Australia|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     24111|     Norway|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     21587|     France|\n",
      "|   536375|    71053|WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|     17850|     12662|    Germany|\n",
      "+---------+---------+-------------------+--------+----------------+---------+----------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Cross join - number of rows is 88566.\n"
     ]
    }
   ],
   "source": [
    "# Cross join\n",
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")\n",
    "\n",
    "df = df_sales.crossJoin(df_customers_nonUK)\n",
    "df.show(10)\n",
    "print(f'Cross join - number of rows is {df.count()}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------------------+--------+----------------+---------+\n",
      "|CustomerID|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+\n",
      "|     17850|   536375|    71053| WHITE METAL LANTERN|       6|01/12/2010 09:32|     3.39|\n",
      "|     17548|  C536391|    21983|PACK OF 12 BLUE P...|     -24|01/12/2010 10:24|     0.29|\n",
      "|     13767|   536395|    21314|SMALL GLASS HEART...|       8|01/12/2010 10:47|      2.1|\n",
      "|     17850|   536396|   82494L|WOODEN FRAME ANTI...|      12|01/12/2010 10:51|     2.55|\n",
      "|     13758|   536425|    22837|HOT WATER BOTTLE ...|       8|01/12/2010 12:08|     4.65|\n",
      "|     14729|   536520|    22760|TRAY, BREAKFAST I...|       1|01/12/2010 12:43|    12.75|\n",
      "|     14729|   536520|    22812|PACK 3 BOXES CHRI...|       3|01/12/2010 12:43|     1.95|\n",
      "|     19224|   536544|    22812|PACK 3 BOXES CHRI...|       2|01/12/2010 14:32|     4.21|\n",
      "|     18657|   536544|   47593B|SCOTTIE DOGS BABY...|       2|01/12/2010 14:32|     0.85|\n",
      "|     17346|   536551|    22551|PLASTERS IN TIN S...|       1|01/12/2010 14:34|     1.65|\n",
      "+----------+---------+---------+--------------------+--------+----------------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Anti join - number of rows is 2162.\n"
     ]
    }
   ],
   "source": [
    "# Anti join\n",
    "df = df_sales.join(df_customers_nonUK , on='CustomerID', how='left_anti')\n",
    "df.show(10)\n",
    "print(f'Anti join - number of rows is {df.count()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task C - Data windowing\n",
    "\n",
    "In relation to a column value (quantity x unit price), and considering a window with some size, how to compute:\n",
    "- a new column whose value is equal to the sum of the current row and previous rows?\n",
    "- the lag?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+----------------+---------+----------+--------------+------------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|CustomerID|       Country|             Value|\n",
      "+---------+---------+--------------------+--------+----------------+---------+----------+--------------+------------------+\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|01/12/2010 08:26|     7.65|     17850|United Kingdom|              15.3|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|01/12/2010 08:26|     3.39|     17850|United Kingdom|             20.34|\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|01/12/2010 08:26|     2.55|     17850|United Kingdom|15.299999999999999|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|01/12/2010 08:26|     4.25|     17850|United Kingdom|              25.5|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|01/12/2010 08:26|     2.75|     17850|United Kingdom|              22.0|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|01/12/2010 08:26|     3.39|     17850|United Kingdom|             20.34|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|01/12/2010 08:26|     3.39|     17850|United Kingdom|             20.34|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|01/12/2010 08:28|     1.85|     17850|United Kingdom|11.100000000000001|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|01/12/2010 08:28|     1.85|     17850|United Kingdom|11.100000000000001|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|01/12/2010 08:34|     5.95|     13047|United Kingdom|             17.85|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|01/12/2010 08:34|     3.75|     13047|United Kingdom|              30.0|\n",
      "|   536367|    48187| DOORMAT NEW ENGLAND|       4|01/12/2010 08:34|     7.95|     13047|United Kingdom|              31.8|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|01/12/2010 08:34|     7.95|     13047|United Kingdom|              31.8|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|01/12/2010 08:34|     1.65|     13047|United Kingdom| 9.899999999999999|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|01/12/2010 08:34|     9.95|     13047|United Kingdom|              19.9|\n",
      "|   536368|    22914|BLUE COAT RACK PA...|       3|01/12/2010 08:34|     4.95|     13047|United Kingdom|14.850000000000001|\n",
      "|   536368|    22912|YELLOW COAT RACK ...|       3|01/12/2010 08:34|     4.95|     13047|United Kingdom|14.850000000000001|\n",
      "|   536368|    22960|JAM MAKING SET WI...|       6|01/12/2010 08:34|     4.25|     13047|United Kingdom|              25.5|\n",
      "|   536368|    22913|RED COAT RACK PAR...|       3|01/12/2010 08:34|     4.95|     13047|United Kingdom|14.850000000000001|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|01/12/2010 08:34|     4.95|     13047|United Kingdom|14.850000000000001|\n",
      "+---------+---------+--------------------+--------+----------------+---------+----------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add value column as quantity * unit price, and then ordered by invoice date\n",
    "df_invoice_value = ( df_retail\n",
    "             .withColumn('Value', F.col('Quantity')*F.col('UnitPrice'))\n",
    "             .orderBy('InvoiceDate')\n",
    "             \n",
    ")\n",
    "df_invoice_value.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkTypeError",
     "evalue": "[NOT_WINDOWSPEC] Argument `window` should be a WindowSpec, got method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m window \u001b[38;5;241m=\u001b[39m Window\u001b[38;5;241m.\u001b[39mpartitionBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerID\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39morderBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvoiceDate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrowsBetween\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 'CustomerID', 'InvoiceDate', ascending=[True, True]\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df_invoice_value\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSumLastSalesForCustomer\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mValue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mover\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/conda/envs/vscode_pyspark/lib/python3.11/site-packages/pyspark/sql/column.py:1392\u001b[0m, in \u001b[0;36mColumn.over\u001b[0;34m(self, window)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwindow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WindowSpec\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(window, WindowSpec):\n\u001b[0;32m-> 1392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   1393\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_WINDOWSPEC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1394\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(window)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   1395\u001b[0m     )\n\u001b[1;32m   1396\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jc\u001b[38;5;241m.\u001b[39mover(window\u001b[38;5;241m.\u001b[39m_jspec)\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_WINDOWSPEC] Argument `window` should be a WindowSpec, got method."
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "# Show a new column related to Value that, for each  invoice/row, \n",
    "# would contain the sum of n previous rows (of column Value)\n",
    "window_previous = -2\n",
    "window = Window.partitionBy('Country', 'CustomerID').orderBy('CustomerID', 'InvoiceDate').rowsBetween\n",
    "# 'CustomerID', 'InvoiceDate', ascending=[True, True]\n",
    "#df_invoice_value.withColumn('SumLastSalesForCustomer',F.sum('Value').over(window_previous)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a new column related to Value that, for each invoice/row, \n",
    "# would contain the value corresponding to a lag of some size (of column Value)\n",
    "window = Window.partitionBy('Country', 'CustomerID').orderBy('CustomerID', 'InvoiceDate')\n",
    "window_size = 2\n",
    "#df_invoice_value.withColumn('PreviousNValueForCustomer',F.lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task D - Spark SQL\n",
    "\n",
    "SQL operations to work with:\n",
    "- Storing the retail data as a persistent table\n",
    "- Use of SQL expressions to query the table, similarly to a DataFrame\n",
    "- Creating a temporary table and then as above query it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the retail data as persistent table into the Hive metastore\n",
    "df_retail.write.mode('overwrite').saveAsTable('RetailTable')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Database(name='default', catalog='spark_catalog', description='default database', locationUri='file:/home/jovyan/code/Notebooks/lab2/spark-warehouse')]\n"
     ]
    }
   ],
   "source": [
    "# List of databases\n",
    "print(spark.catalog.listDatabases())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='retailtable', catalog='spark_catalog', namespace=['default'], description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of tables in the default database\n",
    "spark.catalog.listTables(dbName='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column(name='InvoiceNo', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='StockCode', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='Description', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='Quantity', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='InvoiceDate', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='UnitPrice', description=None, dataType='double', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='CustomerID', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='Country', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of columns in the retail table\n",
    "spark.catalog.listColumns('retailtable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use of the default managed table\n",
    "spark.sql('USE default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 2) (1056678725.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[43], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    spark.sql('SELECT\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "# Show the content of retail table\n",
    "spark.sql('SELECT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary table with just the customers\n",
    "df_customers.createOrReplaceTempView('CustomersTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|CustomerID|Country  |\n",
      "+----------+---------+\n",
      "|12431     |Australia|\n",
      "|19888     |Australia|\n",
      "|19997     |Australia|\n",
      "|20145     |Australia|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CustomerID and country in all rows, with rows order by customerID\n",
    "spark.sql(\"\"\"SELECT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Country       |count|\n",
      "+--------------+-----+\n",
      "|Germany       |4    |\n",
      "|France        |15   |\n",
      "|EIRE          |2    |\n",
      "|Norway        |2    |\n",
      "|Australia     |4    |\n",
      "|United Kingdom|100  |\n",
      "|Netherlands   |2    |\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting of rows regarding each country registered\n",
    "spark.sql(\"\"\"SELECT Country, count(*) as count "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
